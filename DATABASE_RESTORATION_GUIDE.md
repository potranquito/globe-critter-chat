# ğŸ”„ Database Restoration Guide

Your Supabase database was reset, but **all your work is safe** in backup files! This guide will restore everything.

## ğŸ“‹ What Will Be Restored

- âœ… 6 curated ecoregions (Arctic, Congo, Amazon, Madagascar, Borneo, Coral Triangle)
- âœ… 247 curated species with images and descriptions
- âœ… Species-to-ecoregion links
- âœ… All database tables, indexes, and functions
- âœ… Row Level Security (RLS) policies
- âœ… Global health statistics

## ğŸš€ Restoration Steps

### Step 1: Run SQL Script in Supabase

1. **Go to Supabase SQL Editor:**
   https://supabase.com/dashboard/project/jqirupugxgsqgydxaebt/sql

2. **Click "New Query"**

3. **Copy the entire contents of:** `RESTORE_DATABASE_STEP_1.sql`

4. **Paste into the SQL Editor**

5. **Click "Run"**

6. **Wait for completion** (should take 5-10 seconds)

7. **Verify success** - You should see:
   ```
   âœ… Database structure created!
   ecoregions_count: 6
   ```

---

### Step 2: Get Supabase Service Role Key

You need the **Service Role Key** (not the publishable key) to import species.

1. **Go to:** https://supabase.com/dashboard/project/jqirupugxgsqgydxaebt/settings/api

2. **Scroll to "Project API keys"**

3. **Copy the "service_role" key** (starts with `eyJ...`)
   - âš ï¸ **Keep this secret!** Don't commit it to Git

4. **Set environment variable:**
   ```bash
   export SUPABASE_SERVICE_ROLE_KEY="your-service-role-key-here"
   ```

---

### Step 3: Run Python Import Script

1. **Make sure you're in the project directory:**
   ```bash
   cd /home/potranquito/repos/globe-critter-chat
   ```

2. **Activate Python virtual environment (if you have one):**
   ```bash
   source venv/bin/activate
   ```

3. **Install required package (if not already installed):**
   ```bash
   pip install supabase
   ```

4. **Run the import script:**
   ```bash
   python3 restore_species_from_csv.py
   ```

5. **Watch the progress:**
   ```
   ğŸš€ Starting species import from CSV...
   ğŸ“Š Found 247 species in CSV
     âœ“ Imported 25 species...
     âœ“ Imported 50 species...
     ...
   âœ… Import complete!
   ğŸ”— Linking species to ecoregions...
   âœ… Created 247 species-ecoregion links
   ğŸ“Š Updating global health stats...
   ğŸ‰ Database restoration complete!
   ```

---

### Step 4: Verify in Your App

1. **Refresh your browser** at http://localhost:8081

2. **You should now see:**
   - âœ… 6 green ecoregion pins on the globe
   - âœ… Species data when you click an ecoregion
   - âœ… Images and descriptions for species
   - âœ… Conservation status colors

---

## ğŸ” Troubleshooting

### "SUPABASE_SERVICE_ROLE_KEY not found"

Make sure you exported the environment variable:
```bash
export VITE_SUPABASE_URL="https://jqirupugxgsqgydxaebt.supabase.co"
export SUPABASE_SERVICE_ROLE_KEY="your-service-role-key"
```

### "ModuleNotFoundError: No module named 'supabase'"

Install the Supabase Python client:
```bash
pip install supabase
```

### "curated_species_database_enriched.csv not found"

Make sure you're in the project root directory:
```bash
cd /home/potranquito/repos/globe-critter-chat
ls -la curated_species_database_enriched.csv
```

### SQL Script Fails

If the SQL script fails:
1. Check if tables already exist - you may need to drop them first
2. The script includes `DROP TABLE` statements, so it should work even on existing databases
3. If still failing, manually delete tables in Supabase Table Editor first

### Import Script Shows Errors

If some species fail to import:
- The script will continue and import the rest
- Check the error messages for details
- Most errors are due to duplicate scientific names or constraint violations
- The script will still create links for successfully imported species

---

## ğŸ“Š Verification Queries

After restoration, run these in Supabase SQL Editor to verify:

```sql
-- Check ecoregions
SELECT ecoregion_id, name, realm FROM ecoregions ORDER BY name;

-- Check species count
SELECT COUNT(*) as total_species FROM species;

-- Check species by ecoregion
SELECT
  e.name as ecoregion,
  COUNT(s.id) as species_count
FROM ecoregions e
LEFT JOIN species_ecoregions se ON e.id = se.ecoregion_id
LEFT JOIN species s ON se.species_id = s.id
GROUP BY e.name
ORDER BY e.name;

-- Check species with images
SELECT COUNT(*) as species_with_images
FROM species
WHERE image_url IS NOT NULL;

-- Check global health
SELECT * FROM global_health;
```

Expected results:
- 6 ecoregions
- ~247 species (may be slightly less due to duplicates)
- All ecoregions should have species
- Most species should have images
- Global health should show conservation stats

---

## ğŸ¯ What's Next

After restoration:

1. **Test the app** - Click on ecoregions, view species
2. **Check images** - Most species should have images from Wikimedia
3. **Test search** - Search for species names
4. **Verify conservation status colors** - CR=red, EN=orange, VU=yellow, etc.

---

## ğŸ†˜ Still Having Issues?

1. Check the browser console (F12) for errors
2. Verify Supabase connection in .env file
3. Make sure dev server is running: `npm run dev`
4. Check that ecoregions table has 6 rows
5. Check that species table has ~247 rows

---

## ğŸ“ Files Created

- `RESTORE_DATABASE_STEP_1.sql` - SQL script to create all tables
- `restore_species_from_csv.py` - Python script to import species
- `DATABASE_RESTORATION_GUIDE.md` - This file

---

## ğŸ” Security Reminder

**After restoration:**

1. âœ… Revoke the old exposed OpenAI API key at https://platform.openai.com/api-keys
2. âœ… Keep SUPABASE_SERVICE_ROLE_KEY secret (never commit to Git)
3. âœ… The .env file has been removed from GitHub
4. âœ… Your new OpenAI API key is safe in the local .env file

---

**Ready to restore? Start with Step 1!** ğŸš€
